# ğŸ¤– GenAI Usage Analytics Dashboard  
*A complete analytics project to track LLM usage, cost, prompts, and user performance using SQL & Power BI.*

---

## ğŸ“Œ Project Overview  
This project provides a detailed analysis of **Generative AI (LLM) usage** inside an organization.  
The goal is to help teams track:

- Model usage (GPT, Llama, Claude, etc.)  
- Total tokens consumed  
- Prompt/response length behavior  
- Usage by user, department, and model  
- Cost spending on AI models  
- Daily/Monthly usage trends  

Data was cleaned and analyzed using **SQL**, and an interactive dashboard was built using **Power BI** to support decision-making.

---

## ğŸ›  Tech Stack  
| Process | Tools Used |
|---------|------------|
| Data Storage | MySQL / SQL Server |
| Data Cleaning | SQL |
| Data Transformation | Power Query |
| Visualization | Power BI |
| DAX Measures | Used for KPIs & advanced calculations |

---

## ğŸ“‚ Folder Structure  
GenAI-Usage-Analytics/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ genai_usage_raw.csv
â”‚ â”œâ”€â”€ genai_usage_cleaned.csv
â”‚
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ table_schema.sql
â”‚ â”œâ”€â”€ cleaning_queries.sql
â”‚ â”œâ”€â”€ analysis_queries.sql
â”‚
â”œâ”€â”€ powerbi/
â”‚ â”œâ”€â”€ GenAI_Dashboard.pbix
â”‚ â”œâ”€â”€ screenshots/
â”‚
â””â”€â”€ README.md

---

## ğŸ” Project Workflow  

### **1ï¸âƒ£ Data Loading & Cleaning (SQL)**  
- Created `llm_usage` database  
- Loaded raw usage dataset  
- Checked for:  
  - Missing values  
  - Incorrect data types  
  - Duplicate prompt IDs  
- Cleaned and validated data  
- Created important calculated fields:
  - Total Tokens = Prompt Tokens + Completion Tokens  
  - Total Cost  
  - Query Length Category  

---

### **2ï¸âƒ£ Data Analysis (SQL Queries)**  
Performed key analysis using SQL:

- Top users by token usage  
- Most expensive models  
- Tokens used per day  
- Cost per department  
- Average prompt length  
- Peak usage hours  
- LLM performance trends  

---

### **3ï¸âƒ£ Dashboard Development (Power BI)**  
Connected SQL â†’ Power BI and built a multi-page dashboard.

### ğŸ“Š **Dashboard Includes:**

#### â­ **KPI Cards**
- Total Tokens Used  
- Total Cost  
- Total Queries  
- Average Prompt Tokens  
- Average Completion Tokens  

#### ğŸ“ˆ **Visuals**
- Line Chart â†’ Daily Token Usage  
- Bar Chart â†’ Tokens by Model  
- Donut Chart â†’ Cost Share by Model  
- Stacked Bar â†’ Queries by User  
- Table â†’ Detailed Query Logs  
- Filtering Panel â†’ User, Date, Department, Model  

---

## ğŸ“ˆ Key Insights  

âœ” GPT-4o consumes the highest cost but gives best completion quality.  
âœ” Peak usage occurs between **11 AM â€“ 3 PM**.  
âœ” Analysts generate **long prompts**, resulting in high token usage.  
âœ” The top 5 heavy users contribute **60% of the total cost**.  
âœ” Llama models have lower cost with competitive performance for short prompts.  

---

## ğŸš€ Business Value  
This dashboard enables organizations to:  
- Reduce GenAI costs  
- Identify high-usage departments  
- Compare performance of different LLMs  
- Improve prompt writing through token analysis  
- Make strategic decisions on model selection  

---




